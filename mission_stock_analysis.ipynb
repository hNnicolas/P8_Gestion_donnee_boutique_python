{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2b320c",
   "metadata": {},
   "source": [
    "# Mission : Analyse des données & gestion des stocks\n",
    "\n",
    "Notebook généré automatiquement — Phase 1 (agrégation & nettoyage) et Phase 2 (analyses pour le CODIR).\n",
    "\n",
    "Structure :\n",
    "\n",
    "1. Chargement des fichiers\n",
    "2. Rapprochement via la table de liaison\n",
    "3. Détection d'erreurs (≥8 contrôles) et propositions de correction\n",
    "4. Nettoyage / suggestions de pipeline\n",
    "5. Analyses synthétiques pour le CODIR : indicateurs clés, top produits, recommandations\n",
    "\n",
    "_Toutes les étapes sont en français et prêtes à être adaptées selon retours._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a72a379f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/erp.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 5\u001b[0m erp \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/data/erp.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m liaison \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/data/liaison.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m web \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/mnt/data/web.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/erp.csv'"
     ]
    }
   ],
   "source": [
    "# 1) Imports et chargement des fichiers\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "erp = pd.read_csv('/mnt/data/erp.csv')\n",
    "liaison = pd.read_csv('/mnt/data/liaison.csv')\n",
    "web = pd.read_csv('/mnt/data/web.csv')\n",
    "\n",
    "print('ERP shape:', erp.shape)\n",
    "print('Liaison shape:', liaison.shape)\n",
    "print('Web shape:', web.shape)\n",
    "\n",
    "display(erp.head())\n",
    "display(liaison.head())\n",
    "display(web.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ab110",
   "metadata": {},
   "source": [
    "## 2) Rapprochement des tables via la table de liaison\n",
    "\n",
    "Approche :\n",
    "- Normaliser les identifiants (strip, uppercase) avant jointure.\n",
    "- Utiliser une jointure à gauche depuis la table web vers la table liaison puis vers ERP pour conserver ventes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea36500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation et jointures\n",
    "def norm(x):\n",
    "    try:\n",
    "        return str(x).strip().upper()\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "erp['ref_erp_norm'] = erp['reference'].apply(norm) if 'reference' in erp.columns else erp.iloc[:,0].astype(str).apply(norm)\n",
    "liaison['ref_erp_norm'] = liaison.get('ref_erp', liaison.iloc[:,0]).astype(str).apply(norm)\n",
    "liaison['ref_web_norm'] = liaison.get('ref_web', liaison.iloc[:,1] if liaison.shape[1]>1 else liaison.iloc[:,0]).astype(str).apply(norm)\n",
    "web['ref_web_norm'] = web.get('sku', web.iloc[:,0]).astype(str).apply(norm)\n",
    "\n",
    "# Jointure : web -> liaison -> erp\n",
    "web_liaison = web.merge(liaison[['ref_web_norm','ref_erp_norm']], how='left', left_on='ref_web_norm', right_on='ref_web_norm')\n",
    "full = web_liaison.merge(erp, how='left', left_on='ref_erp_norm', right_on='ref_erp_norm', suffixes=('_web','_erp'))\n",
    "\n",
    "print('Jointure terminée. Dimensions resultantes:', full.shape)\n",
    "display(full.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9352b4be-5360-48f3-831f-591a795c6cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation et jointures\n",
    "def norm(x):\n",
    "    try:\n",
    "        return str(x).strip().upper()\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "erp['ref_erp_norm'] = erp['reference'].apply(norm) if 'reference' in erp.columns else erp.iloc[:,0].astype(str).apply(norm)\n",
    "liaison['ref_erp_norm'] = liaison.get('ref_erp', liaison.iloc[:,0]).astype(str).apply(norm)\n",
    "liaison['ref_web_norm'] = liaison.get('ref_web', liaison.iloc[:,1] if liaison.shape[1]>1 else liaison.iloc[:,0]).astype(str).apply(norm)\n",
    "web['ref_web_norm'] = web.get('sku', web.iloc[:,0]).astype(str).apply(norm)\n",
    "\n",
    "# Jointure : web -> liaison -> erp\n",
    "web_liaison = web.merge(liaison[['ref_web_norm','ref_erp_norm']], how='left', left_on='ref_web_norm', right_on='ref_web_norm')\n",
    "full = web_liaison.merge(erp, how='left', left_on='ref_erp_norm', right_on='ref_erp_norm', suffixes=('_web','_erp'))\n",
    "\n",
    "print('Jointure terminée. Dimensions resultantes:', full.shape)\n",
    "display(full.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c67cdc",
   "metadata": {},
   "source": [
    "## 3) Détection d'erreurs (au moins 8 contrôles)\n",
    "\n",
    "Voici une série de contrôles automatisés pour détecter problèmes de qualité de données :\n",
    "\n",
    "1. Identifiants non appariés (web sans ref_erp)\n",
    "2. Doublons dans ERP ou Web\n",
    "3. Types incorrects (ex: quantité vendue non numérique)\n",
    "4. Valeurs négatives (stock, quantités vendues, prix)\n",
    "5. Prix manquants ou nuls\n",
    "6. Totaux incohérents (ex: CA calculé vs CA déclaré si présent)\n",
    "7. Champs texte anormaux (balises HTML, caractères non imprimables)\n",
    "8. Date de vente/flux hors intervalle attendu (si colonne date présente)\n",
    "\n",
    "Chaque contrôle ci-dessous donne un DataFrame d'exemples pour investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Contrôles automatisés\n",
    "checks = {}\n",
    "\n",
    "# 1. web sans liaison vers ERP\n",
    "checks['web_sans_erp'] = full[full['ref_erp_norm'].isna()].copy()\n",
    "\n",
    "# 2. doublons\n",
    "checks['doublons_erp'] = erp[erp.duplicated(subset=['ref_erp_norm'], keep=False)] if 'ref_erp_norm' in erp.columns else pd.DataFrame()\n",
    "checks['doublons_web'] = web[web.duplicated(subset=['ref_web_norm'], keep=False)] if 'ref_web_norm' in web.columns else pd.DataFrame()\n",
    "\n",
    "# 3. types incorrects\n",
    "def to_numeric_errors(s):\n",
    "    try:\n",
    "        conv = pd.to_numeric(s, errors='coerce')\n",
    "        return s[conv.isna() & s.notna()]\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "candidate_cols = []\n",
    "for df,name in [(web,'web'),(erp,'erp')]:\n",
    "    for c in df.columns:\n",
    "        if any(k in c.lower() for k in ['qty','quant','sold','vente','price','prix','stock']):\n",
    "            candidate_cols.append((name,c))\n",
    "for name,c in candidate_cols:\n",
    "    df = web if name=='web' else erp\n",
    "    bad = to_numeric_errors(df[c])\n",
    "    checks[f'type_non_numerique__{name}__{c}'] = df.loc[df[c].isin(list(bad))] if not bad.empty else pd.DataFrame()\n",
    "\n",
    "# 4. valeurs négatives pour stock, quantités, prix\n",
    "for df,name in [(erp,'erp'),(web,'web')]:\n",
    "    for c in df.columns:\n",
    "        if any(k in c.lower() for k in ['qty','quant','sold','vente','stock','price','prix']):\n",
    "            try:\n",
    "                numeric = pd.to_numeric(df[c], errors='coerce')\n",
    "                checks[f'valeurs_negatives__{name}__{c}'] = df.loc[numeric < 0]\n",
    "            except:\n",
    "                checks[f'valeurs_negatives__{name}__{c}'] = pd.DataFrame()\n",
    "\n",
    "# 5. prix manquants ou nuls dans ERP\n",
    "if 'price' in erp.columns or 'prix' in erp.columns:\n",
    "    price_col = 'price' if 'price' in erp.columns else 'prix'\n",
    "    checks['prix_missing_ou_zero'] = erp.loc[erp[price_col].isnull() | (pd.to_numeric(erp[price_col], errors='coerce')==0)]\n",
    "\n",
    "# 6. totaux incohérents : si web contient 'total' ou 'revenue' on compare au calcul\n",
    "if any(c.lower() in ['total','revenue','ca','montant'] for c in web.columns):\n",
    "    for c in web.columns:\n",
    "        if c.lower() in ['total','revenue','ca','montant']:\n",
    "            if 'qty' in web.columns and 'price' in web.columns:\n",
    "                calc = pd.to_numeric(web['qty'], errors='coerce') * pd.to_numeric(web['price'], errors='coerce')\n",
    "                checks['totaux_incoherents'] = web.loc[(pd.to_numeric(web[c], errors='coerce').round(2) != calc.round(2)) & calc.notna()]\n",
    "            break\n",
    "else:\n",
    "    checks['totaux_incoherents'] = pd.DataFrame()\n",
    "\n",
    "# 7. texte anormal (balises html dans description)\n",
    "for df,name in [(web,'web'),(erp,'erp')]:\n",
    "    for c in df.columns:\n",
    "        if any(k in c.lower() for k in ['desc','description','title','name']):\n",
    "            checks[f'texte_html__{name}__{c}'] = df.loc[df[c].astype(str).str.contains('<[^>]+>', regex=True, na=False)]\n",
    "\n",
    "# 8. dates hors intervalle (si colonne date présente)\n",
    "import datetime\n",
    "today = pd.Timestamp.today()\n",
    "for df,name in [(web,'web'),(erp,'erp')]:\n",
    "    for c in df.columns:\n",
    "        if 'date' in c.lower():\n",
    "            try:\n",
    "                dates = pd.to_datetime(df[c], errors='coerce')\n",
    "                checks[f'dates_future__{name}__{c}'] = df.loc[dates > (today + pd.Timedelta(days=1))]\n",
    "            except:\n",
    "                checks[f'dates_future__{name}__{c}'] = pd.DataFrame()\n",
    "\n",
    "for k,v in checks.items():\n",
    "    print(f\"{k}: {len(v)} exemples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57881e55",
   "metadata": {},
   "source": [
    "### Exemples d'erreurs détectées — afficher quelques lignes pour investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b413a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher jusqu'à 10 exemples pour chaque check (s'il y en a)\n",
    "for k,v in checks.items():\n",
    "    if len(v)>0:\n",
    "        print('\\n---', k, '---\\n')\n",
    "        display(v.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a264cdf",
   "metadata": {},
   "source": [
    "## 4) Propositions de correction / pipeline d'amélioration\n",
    "\n",
    "Pour chaque type d'erreur ci-dessus, voici des suggestions concrètes à implémenter côté ERP / Wordpress / ETL :\n",
    "\n",
    "- **Identifiants non appariés** : mettre en place un contrôle à l'import (validation de format), conserver la table de liaison à jour automatiquement via un script de rapprochement quotidien.\n",
    "- **Doublons** : bloquer la création de références identiques, ajouter un UID interne immuable.\n",
    "- **Types / formats** : valider types (prix numeric, qty integer) au niveau des formulaires et imports CSV, ajouter règles strictes dans l'ETL.\n",
    "- **Valeurs négatives** : rejeter ou alerter les valeurs négatives pour stock/quantité/price à la source.\n",
    "- **Prix manquants / nuls** : forcer champ obligatoire et workflow d'activation produit seulement si prix renseigné.\n",
    "- **Texte/HTML** : nettoyer HTML sur description ou stocker contenu HTML dans un champ séparé (raw_html) et une version clean pour le reporting.\n",
    "- **Dates incohérentes** : vérifier fuseau/format et rejeter dates dans le futur sauf si justifié.\n",
    "\n",
    "En plus : créer un script de QA quotidien qui exécute les checks ci-dessus et crée une alerte Slack/email si des anomalies dépassent un seuil.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Exemple de corrections appliquées automatiquement (non destructif: crée de nouvelles colonnes)\n",
    "clean = full.copy()\n",
    "# normaliser prix et quantités\n",
    "for c in clean.columns:\n",
    "    if any(k in c.lower() for k in ['price','prix']):\n",
    "        clean[c+'_num'] = pd.to_numeric(clean[c], errors='coerce')\n",
    "    if any(k in c.lower() for k in ['qty','quant','sold','vente','stock']):\n",
    "        clean[c+'_num'] = pd.to_numeric(clean[c], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# marquer les enregistrements sans correspondance ERP pour revue\n",
    "clean['a_valider_liaison'] = clean['ref_erp_norm'].isna()\n",
    "\n",
    "display(clean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d341b2a8",
   "metadata": {},
   "source": [
    "## 5) Analyses synthétiques pour le CODIR (livrable concis)\n",
    "\n",
    "Indicateurs proposés à présenter (slides 3-6 max) :\n",
    "\n",
    "- **Vision agrégée** : nombre de produits, % produits sans liaison, % produits sans stock, CA total (si données ventes), marge moyenne (si coût dispo).\n",
    "- **Alertes opérationnelles** : top 10 produits avec ventes élevées et stock faible (risque rupture), top 10 avec stock élevé et ventes faibles (sur-stock).\n",
    "- **Qualité données** : nombre d'anomalies détectées par catégorie (8 contrôles ci-dessus).\n",
    "- **Recommandations rapides** : actions court terme (corriger table de liaison, fixer règles d'imports), moyen terme (script QA, dashboard) et long terme (ERP/Shop intégrés).\n",
    "\n",
    "Le code ci-dessous génère ces indicateurs automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37fba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Calculs d'indicateurs simples\n",
    "df = clean.copy()\n",
    "\n",
    "# nombre de produits uniques\n",
    "n_products = df['ref_web_norm'].nunique()\n",
    "pct_sans_liaison = df['a_valider_liaison'].mean() * 100\n",
    "\n",
    "# CA si qty * price present (essayer de détecter colonnes)\n",
    "qty_col = None\n",
    "price_col = None\n",
    "for c in df.columns:\n",
    "    if 'qty' in c.lower() and c.endswith('_num'):\n",
    "        qty_col = c\n",
    "    if ('price' in c.lower() or 'prix' in c.lower()) and c.endswith('_num'):\n",
    "        price_col = c\n",
    "\n",
    "ca_total = None\n",
    "if qty_col and price_col:\n",
    "    df['ca_calc'] = df[qty_col] * df[price_col]\n",
    "    ca_total = df['ca_calc'].sum()\n",
    "\n",
    "print(f\"Nombre de produits (web): {n_products}\")\n",
    "print(f\"% produits sans liaison ERP: {pct_sans_liaison:.1f}%\")\n",
    "if ca_total is not None:\n",
    "    print(f\"CA calculé (approx): {ca_total:.2f}\")\n",
    "else:\n",
    "    print('CA non calculable : colonnes qty/price manquantes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top produits à risque / sur-stock (si données qty & stock présentes)\n",
    "# tenter de localiser colonnes de stock\n",
    "stock_cols = [c for c in df.columns if 'stock' in c.lower() or 'qty' in c.lower() or 'quant' in c.lower()]\n",
    "print('Colonnes candidates pour stock/qty:', stock_cols)\n",
    "\n",
    "# Top 10 ventes (par ca_calc)\n",
    "if 'ca_calc' in df.columns:\n",
    "    top_ventes = df.groupby('ref_web_norm')['ca_calc'].sum().sort_values(ascending=False).head(10)\n",
    "    print('\\nTop 10 CA par produit (ref_web_norm):')\n",
    "    display(top_ventes)\n",
    "\n",
    "# Top risque rupture : ventes élevées / stock faible (si stock_col exists)\n",
    "if stock_cols:\n",
    "    stock_col = stock_cols[0]\n",
    "    ventes_par_produit = df.groupby('ref_web_norm')[qty_col].sum() if qty_col else pd.Series(dtype=float)\n",
    "    merged = pd.DataFrame({'ventes': ventes_par_produit, 'stock': df.groupby('ref_web_norm')[stock_col].first()})\n",
    "    merged = merged.fillna(0)\n",
    "    merged['ratio_ventes_stock'] = merged['ventes'] / (merged['stock'] + 1)\n",
    "    top_risque = merged.sort_values('ratio_ventes_stock', ascending=False).head(10)\n",
    "    print('\\nTop 10 risque rupture (ventes/stock):')\n",
    "    display(top_risque)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fdc6b",
   "metadata": {},
   "source": [
    "### Recommandations synthétiques (slide pour CODIR)\n",
    "\n",
    "1. **Court terme (1-2 semaines)**\n",
    "- Corriger les 20 premières références non appariées et anomalies critiques (prix nuls, valeurs négatives).\n",
    "- Mettre en place contrôle à l'import CSV et script QA quotidien.\n",
    "\n",
    "2. **Moyen terme (1-3 mois)**\n",
    "- Automatiser la synchronisation table de liaison ou standardiser les identifiants.\n",
    "- Dashboard KPI (stock, CA, rotations) pour le suivi hebdomadaire.\n",
    "\n",
    "3. **Long terme**\n",
    "- Intégration ERP-Shop (ou middleware) pour éviter double saisie.\n",
    "- Refonte du process d'activation produit (workflow) pour garantir qualité des données.\n",
    "\n",
    "Fin — notebook prêt à être adapté pour la présentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
