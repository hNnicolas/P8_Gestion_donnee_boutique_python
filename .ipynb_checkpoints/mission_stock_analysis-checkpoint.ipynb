{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2b320c",
   "metadata": {},
   "source": [
    "# Mission : Analyse des données & gestion des stocks\n",
    "\n",
    "Notebook généré automatiquement — Phase 1 (agrégation & nettoyage) et Phase 2 (analyses pour le CODIR).\n",
    "\n",
    "Structure :\n",
    "\n",
    "1. Chargement des fichiers\n",
    "2. Rapprochement via la table de liaison\n",
    "3. Détection d'erreurs (≥8 contrôles) et propositions de correction\n",
    "4. Nettoyage / suggestions de pipeline\n",
    "5. Analyses synthétiques pour le CODIR : indicateurs clés, top produits, recommandations\n",
    "\n",
    "_Toutes les étapes sont en français et prêtes à être adaptées selon retours._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72a379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports et chargement des fichiers\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "erp = pd.read_csv('/mnt/data/erp.csv')\n",
    "liaison = pd.read_csv('/mnt/data/liaison.csv')\n",
    "web = pd.read_csv('/mnt/data/web.csv')\n",
    "\n",
    "print('ERP shape:', erp.shape)\n",
    "print('Liaison shape:', liaison.shape)\n",
    "print('Web shape:', web.shape)\n",
    "\n",
    "display(erp.head())\n",
    "display(liaison.head())\n",
    "display(web.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5ab110",
   "metadata": {},
   "source": [
    "## 2) Rapprochement des tables via la table de liaison\n",
    "\n",
    "Approche :\n",
    "- Normaliser les identifiants (strip, uppercase) avant jointure.\n",
    "- Utiliser une jointure à gauche depuis la table web vers la table liaison puis vers ERP pour conserver ventes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea36500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation et jointures\n",
    "def norm(x):\n",
    "    try:\n",
    "        return str(x).strip().upper()\n",
    "    except:\n",
    "        return x\n",
    "\n",
    "erp['ref_erp_norm'] = erp['reference'].apply(norm) if 'reference' in erp.columns else erp.iloc[:,0].astype(str).apply(norm)\n",
    "liaison['ref_erp_norm'] = liaison.get('ref_erp', liaison.iloc[:,0]).astype(str).apply(norm)\n",
    "liaison['ref_web_norm'] = liaison.get('ref_web', liaison.iloc[:,1] if liaison.shape[1]>1 else liaison.iloc[:,0]).astype(str).apply(norm)\n",
    "web['ref_web_norm'] = web.get('sku', web.iloc[:,0]).astype(str).apply(norm)\n",
    "\n",
    "# Jointure : web -> liaison -> erp\n",
    "web_liaison = web.merge(liaison[['ref_web_norm','ref_erp_norm']], how='left', left_on='ref_web_norm', right_on='ref_web_norm')\n",
    "full = web_liaison.merge(erp, how='left', left_on='ref_erp_norm', right_on='ref_erp_norm', suffixes=('_web','_erp'))\n",
    "\n",
    "print('Jointure terminée. Dimensions resultantes:', full.shape)\n",
    "display(full.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c67cdc",
   "metadata": {},
   "source": [
    "## 3) Détection d'erreurs (au moins 8 contrôles)\n",
    "\n",
    "Voici une série de contrôles automatisés pour détecter problèmes de qualité de données :\n",
    "\n",
    "1. Identifiants non appariés (web sans ref_erp)\n",
    "2. Doublons dans ERP ou Web\n",
    "3. Types incorrects (ex: quantité vendue non numérique)\n",
    "4. Valeurs négatives (stock, quantités vendues, prix)\n",
    "5. Prix manquants ou nuls\n",
    "6. Totaux incohérents (ex: CA calculé vs CA déclaré si présent)\n",
    "7. Champs texte anormaux (balises HTML, caractères non imprimables)\n",
    "8. Date de vente/flux hors intervalle attendu (si colonne date présente)\n",
    "\n",
    "Chaque contrôle ci-dessous donne un DataFrame d'exemples pour investigation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf7063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Contrôles automatisés\n",
    "checks = {}\n",
    "\n",
    "# 1. web sans liaison vers ERP\n",
    "checks['web_sans_erp'] = full[full['ref_erp_norm'].isna()].copy()\n",
    "\n",
    "# 2. doublons\n",
    "checks['doublons_erp'] = erp[erp.duplicated(subset=['ref_erp_norm'], keep=False)] if 'ref_erp_norm' in erp.columns else pd.DataFrame()\n",
    "checks['doublons_web'] = web[web.duplicated(subset=['ref_web_norm'], keep=False)] if 'ref_web_norm' in web.columns else pd.DataFrame()\n",
    "\n",
    "# 3. types incorrects\n",
    "def to_numeric_errors(s):\n",
    "    try:\n",
    "        conv = pd.to_numeric(s, errors='coerce')\n",
    "        return s[conv.isna() & s.notna()]\n",
    "    except:\n",
    "        return s\n",
    "\n",
    "candidate_cols = []\n",
    "for df,name in [(web,'web'),(erp,'erp')]:\n",
    "    for c in df.columns:\n",
    "        if any(k in c.lower() for k in ['qty','quant','sold','vente','price','prix','stock']):\n",
    "            candidate_cols.append((name,c))\n",
    "for name,c in candidate_cols:\n",
    "    df = web if name=='web' else erp\n",
    "    bad = to_numeric_errors(df[c])\n",
    "    checks[f'type_non_numerique__{name}__{c}'] = df.loc[df[c].isin(list(bad))] if not bad.empty else pd.DataFrame()\n",
    "\n",
    "# 4. valeurs négatives pour stock, quantités, prix\n",
    "for df,name in [(erp,'erp'),(web,'web')]:\n",
    "    for c in df.columns:\n",
    "        if any(k in c.lower() for k in ['qty','quant','sold','vente','stock','price','prix']):\n",
    "            try:\n",
    "                numeric = pd.to_numeric(df[c], errors='coerce')\n",
    "                checks[f'valeurs_negatives__{name}__{c}'] = df.loc[numeric < 0]\n",
    "            except:\n",
    "                checks[f'valeurs_negatives__{name}__{c}'] = pd.DataFrame()\n",
    "\n",
    "# 5. prix manquants ou nuls dans ERP\n",
    "if 'price' in erp.columns or 'prix' in erp.columns:\n",
    "    price_col = 'price' if 'price' in erp.columns else 'prix'\n",
    "    checks['prix_missing_ou_zero'] = erp.loc[erp[price_col].isnull() | (pd.to_numeric(erp[price_col], errors='coerce')==0)]\n",
    "\n",
    "# 6. totaux incohérents : si web contient 'total' ou 'revenue' on compare au calcul\n",
    "if any(c.lower() in ['total','revenue','ca','montant'] for c in web.columns):\n",
    "    for c in web.columns:\n",
    "        if c.lower() in ['total','revenue','ca','montant']:\n",
    "            if 'qty' in web.columns and 'price' in web.columns:\n",
    "                calc = pd.to_numeric(web['qty'], errors='coerce') * pd.to_numeric(web['price'], errors='coerce')\n",
    "                checks['totaux_incoherents'] = web.loc[(pd.to_numeric(web[c], errors='coerce').round(2) != calc.round(2)) & calc.notna()]\n",
    "            break\n",
    "else:\n",
    "    checks['totaux_incoherents'] = pd.DataFrame()\n",
    "\n",
    "# 7. texte anormal (balises html dans description)\n",
    "for df,name in [(web,'web'),(erp,'erp')]:\n",
    "    for c in df.columns:\n",
    "        if any(k in c.lower() for k in ['desc','description','title','name']):\n",
    "            checks[f'texte_html__{name}__{c}'] = df.loc[df[c].astype(str).str.contains('<[^>]+>', regex=True, na=False)]\n",
    "\n",
    "# 8. dates hors intervalle (si colonne date présente)\n",
    "import datetime\n",
    "today = pd.Timestamp.today()\n",
    "for df,name in [(web,'web'),(erp,'erp')]:\n",
    "    for c in df.columns:\n",
    "        if 'date' in c.lower():\n",
    "            try:\n",
    "                dates = pd.to_datetime(df[c], errors='coerce')\n",
    "                checks[f'dates_future__{name}__{c}'] = df.loc[dates > (today + pd.Timedelta(days=1))]\n",
    "            except:\n",
    "                checks[f'dates_future__{name}__{c}'] = pd.DataFrame()\n",
    "\n",
    "for k,v in checks.items():\n",
    "    print(f\"{k}: {len(v)} exemples\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57881e55",
   "metadata": {},
   "source": [
    "### Exemples d'erreurs détectées — afficher quelques lignes pour investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b413a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher jusqu'à 10 exemples pour chaque check (s'il y en a)\n",
    "for k,v in checks.items():\n",
    "    if len(v)>0:\n",
    "        print('\\n---', k, '---\\n')\n",
    "        display(v.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a264cdf",
   "metadata": {},
   "source": [
    "## 4) Propositions de correction / pipeline d'amélioration\n",
    "\n",
    "Pour chaque type d'erreur ci-dessus, voici des suggestions concrètes à implémenter côté ERP / Wordpress / ETL :\n",
    "\n",
    "- **Identifiants non appariés** : mettre en place un contrôle à l'import (validation de format), conserver la table de liaison à jour automatiquement via un script de rapprochement quotidien.\n",
    "- **Doublons** : bloquer la création de références identiques, ajouter un UID interne immuable.\n",
    "- **Types / formats** : valider types (prix numeric, qty integer) au niveau des formulaires et imports CSV, ajouter règles strictes dans l'ETL.\n",
    "- **Valeurs négatives** : rejeter ou alerter les valeurs négatives pour stock/quantité/price à la source.\n",
    "- **Prix manquants / nuls** : forcer champ obligatoire et workflow d'activation produit seulement si prix renseigné.\n",
    "- **Texte/HTML** : nettoyer HTML sur description ou stocker contenu HTML dans un champ séparé (raw_html) et une version clean pour le reporting.\n",
    "- **Dates incohérentes** : vérifier fuseau/format et rejeter dates dans le futur sauf si justifié.\n",
    "\n",
    "En plus : créer un script de QA quotidien qui exécute les checks ci-dessus et crée une alerte Slack/email si des anomalies dépassent un seuil.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f24c361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Exemple de corrections appliquées automatiquement (non destructif: crée de nouvelles colonnes)\n",
    "clean = full.copy()\n",
    "# normaliser prix et quantités\n",
    "for c in clean.columns:\n",
    "    if any(k in c.lower() for k in ['price','prix']):\n",
    "        clean[c+'_num'] = pd.to_numeric(clean[c], errors='coerce')\n",
    "    if any(k in c.lower() for k in ['qty','quant','sold','vente','stock']):\n",
    "        clean[c+'_num'] = pd.to_numeric(clean[c], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# marquer les enregistrements sans correspondance ERP pour revue\n",
    "clean['a_valider_liaison'] = clean['ref_erp_norm'].isna()\n",
    "\n",
    "display(clean.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d341b2a8",
   "metadata": {},
   "source": [
    "## 5) Analyses synthétiques pour le CODIR (livrable concis)\n",
    "\n",
    "Indicateurs proposés à présenter (slides 3-6 max) :\n",
    "\n",
    "- **Vision agrégée** : nombre de produits, % produits sans liaison, % produits sans stock, CA total (si données ventes), marge moyenne (si coût dispo).\n",
    "- **Alertes opérationnelles** : top 10 produits avec ventes élevées et stock faible (risque rupture), top 10 avec stock élevé et ventes faibles (sur-stock).\n",
    "- **Qualité données** : nombre d'anomalies détectées par catégorie (8 contrôles ci-dessus).\n",
    "- **Recommandations rapides** : actions court terme (corriger table de liaison, fixer règles d'imports), moyen terme (script QA, dashboard) et long terme (ERP/Shop intégrés).\n",
    "\n",
    "Le code ci-dessous génère ces indicateurs automatiquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37fba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Calculs d'indicateurs simples\n",
    "df = clean.copy()\n",
    "\n",
    "# nombre de produits uniques\n",
    "n_products = df['ref_web_norm'].nunique()\n",
    "pct_sans_liaison = df['a_valider_liaison'].mean() * 100\n",
    "\n",
    "# CA si qty * price present (essayer de détecter colonnes)\n",
    "qty_col = None\n",
    "price_col = None\n",
    "for c in df.columns:\n",
    "    if 'qty' in c.lower() and c.endswith('_num'):\n",
    "        qty_col = c\n",
    "    if ('price' in c.lower() or 'prix' in c.lower()) and c.endswith('_num'):\n",
    "        price_col = c\n",
    "\n",
    "ca_total = None\n",
    "if qty_col and price_col:\n",
    "    df['ca_calc'] = df[qty_col] * df[price_col]\n",
    "    ca_total = df['ca_calc'].sum()\n",
    "\n",
    "print(f\"Nombre de produits (web): {n_products}\")\n",
    "print(f\"% produits sans liaison ERP: {pct_sans_liaison:.1f}%\")\n",
    "if ca_total is not None:\n",
    "    print(f\"CA calculé (approx): {ca_total:.2f}\")\n",
    "else:\n",
    "    print('CA non calculable : colonnes qty/price manquantes')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623a044f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top produits à risque / sur-stock (si données qty & stock présentes)\n",
    "# tenter de localiser colonnes de stock\n",
    "stock_cols = [c for c in df.columns if 'stock' in c.lower() or 'qty' in c.lower() or 'quant' in c.lower()]\n",
    "print('Colonnes candidates pour stock/qty:', stock_cols)\n",
    "\n",
    "# Top 10 ventes (par ca_calc)\n",
    "if 'ca_calc' in df.columns:\n",
    "    top_ventes = df.groupby('ref_web_norm')['ca_calc'].sum().sort_values(ascending=False).head(10)\n",
    "    print('\\nTop 10 CA par produit (ref_web_norm):')\n",
    "    display(top_ventes)\n",
    "\n",
    "# Top risque rupture : ventes élevées / stock faible (si stock_col exists)\n",
    "if stock_cols:\n",
    "    stock_col = stock_cols[0]\n",
    "    ventes_par_produit = df.groupby('ref_web_norm')[qty_col].sum() if qty_col else pd.Series(dtype=float)\n",
    "    merged = pd.DataFrame({'ventes': ventes_par_produit, 'stock': df.groupby('ref_web_norm')[stock_col].first()})\n",
    "    merged = merged.fillna(0)\n",
    "    merged['ratio_ventes_stock'] = merged['ventes'] / (merged['stock'] + 1)\n",
    "    top_risque = merged.sort_values('ratio_ventes_stock', ascending=False).head(10)\n",
    "    print('\\nTop 10 risque rupture (ventes/stock):')\n",
    "    display(top_risque)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fdc6b",
   "metadata": {},
   "source": [
    "### Recommandations synthétiques (slide pour CODIR)\n",
    "\n",
    "1. **Court terme (1-2 semaines)**\n",
    "- Corriger les 20 premières références non appariées et anomalies critiques (prix nuls, valeurs négatives).\n",
    "- Mettre en place contrôle à l'import CSV et script QA quotidien.\n",
    "\n",
    "2. **Moyen terme (1-3 mois)**\n",
    "- Automatiser la synchronisation table de liaison ou standardiser les identifiants.\n",
    "- Dashboard KPI (stock, CA, rotations) pour le suivi hebdomadaire.\n",
    "\n",
    "3. **Long terme**\n",
    "- Intégration ERP-Shop (ou middleware) pour éviter double saisie.\n",
    "- Refonte du process d'activation produit (workflow) pour garantir qualité des données.\n",
    "\n",
    "Fin — notebook prêt à être adapté pour la présentation."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
